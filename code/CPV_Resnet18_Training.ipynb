{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "078tE8Cg5Fcn",
        "outputId": "3a309917-9154-4e12-d80b-8878e8458e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 15 02:31:19 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from utils import download_list, drive_download\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "G0IckMbj5I5Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_list(49, \"npz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIPqxJb5Tf7",
        "outputId": "4b902db7-94b6-4196-d6f0-3e09983bf97a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading k49-train-imgs.npz - 64.6 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64569/64569 [00:46<00:00, 1389.75KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading k49-train-labels.npz - 0.2 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161/161 [00:00<00:00, 242.09KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading k49-test-imgs.npz - 10.7 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10715/10715 [00:14<00:00, 740.64KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading k49-test-labels.npz - 0.0 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [00:00<00:00, 122.23KB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataset files downloaded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.load('./k49-train-imgs.npz')['arr_0']\n",
        "test_images = np.load('./k49-test-imgs.npz')['arr_0']\n",
        "train_labels = np.load('./k49-train-labels.npz')['arr_0']\n",
        "test_labels = np.load('./k49-test-labels.npz')['arr_0']"
      ],
      "metadata": {
        "id": "gDU76HGr5VhB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class JPDDataset(Dataset):\n",
        "\n",
        "    def __init__(self, images, labels):\n",
        "        # self._process_images(images)\n",
        "        self.images = torch.from_numpy(images / 255.0)\n",
        "        self.labels = torch.from_numpy(labels)\n",
        "        # self.transform = transforms.Compose([\n",
        "        #     transforms.Normalize((0.5), (0.5))\n",
        "        # ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = torch.zeros((49))\n",
        "        label[int(self.labels[idx])] = 1.0\n",
        "        # image = self.transform(image)\n",
        "        return image.float().unsqueeze(0), label"
      ],
      "metadata": {
        "id": "UWP8HOLM5W6J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(train_images, train_label, test_images, test_labels, batch_size):\n",
        "    train_data = JPDDataset(train_images, train_labels)\n",
        "    valid_data = JPDDataset(test_images, test_labels)\n",
        "    print(f\"Train: {len(train_data)} samples, Valid: {len(valid_data)} samples\")\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
        "    print(f\"Train: {len(train_loader)} batches, Valid: {len(valid_loader)} batches\")\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "z_E9R08p5XQP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, valid_loader = get_loader(train_images, train_labels, test_images, test_labels, 2048)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pn9AVHQ5XS3",
        "outputId": "c9855df1-19e8-4a6c-d1b2-f911a69432f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 232365 samples, Valid: 38547 samples\n",
            "Train: 114 batches, Valid: 19 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (X, y) in enumerate(train_loader):\n",
        "    print(X.size(), y.size())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3ZoglTN5XVN",
        "outputId": "b1a5f948-b80f-458e-9a2f-f2209d8d9a56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2048, 1, 28, 28]) torch.Size([2048, 49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "from datetime import timedelta\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        scheduler=None\n",
        "    ):\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.scheduler = scheduler\n",
        "        self.threshold = 0.65\n",
        "        self.cache = {\n",
        "            \"train_loss\": [],\n",
        "            \"valid_loss\": [],\n",
        "            \"train_acc\": [],\n",
        "            \"valid_acc\": [],\n",
        "            \"lr\": [],\n",
        "        }\n",
        "    #\n",
        "\n",
        "    def load_checkpoint(self, path):\n",
        "        params = torch.load(path)\n",
        "        self.model.load_state_dict(params[\"model\"])\n",
        "        self.optimizer.load_state_dict(params[\"optimizer\"])\n",
        "        if self.scheduler is not None:\n",
        "            self.scheduler.load_state_dict(params[\"scheduler\"])\n",
        "        self.cache = params[\"cache\"]\n",
        "        print(\"[+] Model load successful\")\n",
        "    #\n",
        "\n",
        "    def save_checkpoint(self, path):\n",
        "        params = {\n",
        "            \"model\": self.model.state_dict(),\n",
        "            \"optimizer\": self.optimizer.state_dict(),\n",
        "            \"scheduler\": None if self.scheduler is None else self.scheduler.state_dict(),\n",
        "            \"cache\": self.cache\n",
        "        }\n",
        "        torch.save(params, path)\n",
        "        print(\"[+] Save checkpoint successfully\")\n",
        "    #\n",
        "\n",
        "    def compute_metrics(self, preds, labels):\n",
        "        labels = labels.cpu().detach().numpy()\n",
        "        preds = preds.cpu().detach()\n",
        "        if preds.ndim == 1:\n",
        "            preds = preds.unsqueeze(0)\n",
        "        preds = torch.sigmoid(preds).numpy()\n",
        "        preds[preds >= self.threshold] = 1.0\n",
        "        preds[preds < 1.0] = 0\n",
        "        accuracy = accuracy_score(labels, preds)\n",
        "        precision = precision_score(labels, preds, average='weighted', zero_division=1)\n",
        "        recall = recall_score(labels, preds, average='weighted', zero_division=1)\n",
        "        f1 = f1_score(labels, preds, average='weighted', zero_division=1)\n",
        "        return {\n",
        "            'accuracy': round(accuracy, 3),\n",
        "            'precision': round(precision, 3),\n",
        "            'recall': round(recall, 3),\n",
        "            'f1': round(f1, 3),\n",
        "        }\n",
        "    #\n",
        "\n",
        "    def forward(self, dataloader, train_mode=\"Train\"):\n",
        "        if train_mode == \"Train\":\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "        loss_his = []\n",
        "        acc_his = []\n",
        "        N = len(dataloader)\n",
        "        self.cache_valid = {\n",
        "            \"logits\": [],\n",
        "            \"labels\": []\n",
        "        }\n",
        "        for idx, (images, labels) in enumerate(dataloader, 1):\n",
        "            if train_mode == \"Train\":\n",
        "                self.optimizer.zero_grad()\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            if train_mode == \"Train\":\n",
        "                logits = self.model(images)\n",
        "                loss = self.criterion(logits, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                if self.scheduler is not None:\n",
        "                    self.scheduler.step()\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    logits = self.model(images)\n",
        "                    loss = self.criterion(logits, labels)\n",
        "            acc = self.compute_metrics(logits, labels)\n",
        "            loss_his.append(loss.item())\n",
        "            acc_his.append(acc)\n",
        "\n",
        "            log_info = {\n",
        "                train_mode: f\" batch: {idx} / {N}\",\n",
        "                \"loss\": f\": {round(loss_his[-1], 5)}\",\n",
        "                \"accuracy\": f\": {acc['accuracy']}\",\n",
        "                \"precision\": f\": {acc['precision']}\",\n",
        "                \"recall\": f\": {acc['recall']}\",\n",
        "                \"f1\": f\": {acc['f1']}\"\n",
        "            }\n",
        "            log_info = [str(k) + str(v) for k, v in log_info.items()]\n",
        "            log_info = \" - \".join(log_info)\n",
        "            print(\"\\r\", end=\"\")\n",
        "            print(log_info, end=\"\" if idx != N else \"\\n\")\n",
        "\n",
        "        loss_his = sum(loss_his) / len(loss_his)\n",
        "        acc_his = {\n",
        "            \"accuracy\": sum([i['accuracy'] for i in acc_his]) / len(acc_his),\n",
        "            \"precision\": sum([i['precision'] for i in acc_his]) / len(acc_his),\n",
        "            \"recall\": sum([i['recall'] for i in acc_his]) / len(acc_his),\n",
        "            \"f1\": sum([i['f1'] for i in acc_his]) / len(acc_his),\n",
        "        }\n",
        "        acc_his = {\n",
        "            k : round(float(v), 3) for k , v in acc_his.items()\n",
        "        }\n",
        "        if train_mode == \"Train\":\n",
        "            self.cache[\"train_loss\"].append(loss_his)\n",
        "            self.cache[\"train_acc\"].append(acc_his)\n",
        "        else:\n",
        "            self.cache[\"valid_loss\"].append(loss_his)\n",
        "            self.cache[\"valid_acc\"].append(acc_his)\n",
        "    #\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        train_loader,\n",
        "        valid_loader=None,\n",
        "        epochs=10,\n",
        "        checkpoint=\"./checkpoint.pt\"\n",
        "    ):\n",
        "        print(f\"Running on: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
        "        print(f\"Total update step: {len(train_loader) * epochs}\")\n",
        "\n",
        "        for epoch in range(1, epochs+1):\n",
        "            start_time = time.time()\n",
        "            print(f\"Epoch: {epoch}\")\n",
        "            logs = []\n",
        "            current_lr = f\": {self.optimizer.param_groups[0]['lr']:.5}\"\n",
        "            try:\n",
        "                self.forward(train_loader)\n",
        "                train_loss = round(self.cache[\"train_loss\"][-1], 5)\n",
        "                train_acc = [str(k) + \": \" + str(v) for k, v in self.cache[\"train_acc\"][-1].items()]\n",
        "                train_acc = \" - \".join(train_acc)\n",
        "                logs.append(f\"\\t=> Train epoch: loss: {train_loss} - {train_acc}\")\n",
        "            except KeyboardInterrupt:\n",
        "                sys.exit()\n",
        "            if valid_loader is not None:\n",
        "                try:\n",
        "                    self.forward(valid_loader, \"Valid\")\n",
        "                    valid_loss = round(self.cache[\"valid_loss\"][-1], 5)\n",
        "                    valid_acc = [str(k) + \": \" + str(v) for k, v in self.cache[\"valid_acc\"][-1].items()]\n",
        "                    valid_acc = \" - \".join(valid_acc)\n",
        "                    logs.append(f\"\\t=> Valid epoch: loss: {valid_loss} - {valid_acc}\")\n",
        "                except KeyboardInterrupt:\n",
        "                    sys.exit()\n",
        "            total_time = round(time.time() - start_time, 1)\n",
        "            logs.append(f\"\\t=> Learning Rate: {current_lr} - Time: {timedelta(seconds=int(total_time))}/step\\n\")\n",
        "            print(\"\\n\".join(logs))\n",
        "            self.cache[\"lr\"].append(current_lr)\n",
        "            self.save_checkpoint(checkpoint)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0tFxQE-B5XaD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "def create_model(input_dim, num_classes=49):\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    model.conv1 = torch.nn.Conv2d(input_dim, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "    model.fc = torch.nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ra1D2ZFM6OH4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(1)\n",
        "# model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2iRk-xi6Tme",
        "outputId": "03812a16-a67f-4944-d2e2-ee6ca77b9089"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(),\n",
        "    lr=1e-3,\n",
        "    betas=(0.9, 0.999),\n",
        "    eps=1e-08,\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=len(train_loader)*2, gamma=0.5)"
      ],
      "metadata": {
        "id": "T4Q739Iq6IrZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, optimizer, criterion, scheduler)\n",
        "# trainer.load_checkpoint()"
      ],
      "metadata": {
        "id": "nK9I2XNp6KYW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(train_loader, valid_loader, 20, \"./checkpoint/model_v1.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nqvvIAit6KrJ",
        "outputId": "9397d453-1c74-4615-ef21-f6696f7e5a98"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: Tesla T4\n",
            "Total update step: 2280\n",
            "Epoch: 1\n",
            "Train batch: 114 / 114 - loss: 0.01293 - accuracy: 0.825 - precision: 0.954 - recall: 0.825 - f1: 0.879\n",
            "Valid batch: 19 / 19 - loss: 0.02516 - accuracy: 0.678 - precision: 0.912 - recall: 0.679 - f1: 0.769\n",
            "\t=> Train epoch: loss: 0.06726 - accuracy: 0.426 - precision: 0.916 - recall: 0.431 - f1: 0.485\n",
            "\t=> Valid epoch: loss: 0.0245 - accuracy: 0.684 - precision: 0.919 - recall: 0.685 - f1: 0.773\n",
            "\t=> Learning Rate: : 0.001 - Time: 0:00:53/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 2\n",
            "Train batch: 114 / 114 - loss: 0.00744 - accuracy: 0.917 - precision: 0.967 - recall: 0.917 - f1: 0.939\n",
            "Valid batch: 19 / 19 - loss: 0.01226 - accuracy: 0.846 - precision: 0.955 - recall: 0.847 - f1: 0.894\n",
            "\t=> Train epoch: loss: 0.00783 - accuracy: 0.902 - precision: 0.972 - recall: 0.902 - f1: 0.934\n",
            "\t=> Valid epoch: loss: 0.0117 - accuracy: 0.854 - precision: 0.959 - recall: 0.854 - f1: 0.901\n",
            "\t=> Learning Rate: : 0.001 - Time: 0:00:52/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 3\n",
            "Train batch: 114 / 114 - loss: 0.00446 - accuracy: 0.95 - precision: 0.982 - recall: 0.95 - f1: 0.965\n",
            "Valid batch: 19 / 19 - loss: 0.00793 - accuracy: 0.904 - precision: 0.969 - recall: 0.904 - f1: 0.934\n",
            "\t=> Train epoch: loss: 0.00416 - accuracy: 0.951 - precision: 0.985 - recall: 0.951 - f1: 0.967\n",
            "\t=> Valid epoch: loss: 0.00893 - accuracy: 0.896 - precision: 0.967 - recall: 0.896 - f1: 0.928\n",
            "\t=> Learning Rate: : 0.0005 - Time: 0:00:52/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 4\n",
            "Train batch: 114 / 114 - loss: 0.00297 - accuracy: 0.959 - precision: 0.989 - recall: 0.959 - f1: 0.973\n",
            "Valid batch: 19 / 19 - loss: 0.00814 - accuracy: 0.905 - precision: 0.971 - recall: 0.905 - f1: 0.934\n",
            "\t=> Train epoch: loss: 0.00309 - accuracy: 0.964 - precision: 0.989 - recall: 0.964 - f1: 0.976\n",
            "\t=> Valid epoch: loss: 0.00873 - accuracy: 0.901 - precision: 0.966 - recall: 0.901 - f1: 0.931\n",
            "\t=> Learning Rate: : 0.0005 - Time: 0:00:53/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 5\n",
            "Train batch: 114 / 114 - loss: 0.00255 - accuracy: 0.973 - precision: 0.992 - recall: 0.973 - f1: 0.982\n",
            "Valid batch: 19 / 19 - loss: 0.00748 - accuracy: 0.926 - precision: 0.975 - recall: 0.926 - f1: 0.948\n",
            "\t=> Train epoch: loss: 0.00208 - accuracy: 0.977 - precision: 0.994 - recall: 0.977 - f1: 0.985\n",
            "\t=> Valid epoch: loss: 0.00723 - accuracy: 0.92 - precision: 0.973 - recall: 0.92 - f1: 0.944\n",
            "\t=> Learning Rate: : 0.00025 - Time: 0:00:53/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 6\n",
            "Train batch: 114 / 114 - loss: 0.00177 - accuracy: 0.981 - precision: 0.993 - recall: 0.981 - f1: 0.986\n",
            "Valid batch: 19 / 19 - loss: 0.00751 - accuracy: 0.916 - precision: 0.972 - recall: 0.917 - f1: 0.943\n",
            "\t=> Train epoch: loss: 0.0016 - accuracy: 0.983 - precision: 0.996 - recall: 0.983 - f1: 0.989\n",
            "\t=> Valid epoch: loss: 0.00722 - accuracy: 0.923 - precision: 0.972 - recall: 0.924 - f1: 0.946\n",
            "\t=> Learning Rate: : 0.00025 - Time: 0:00:52/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 7\n",
            "Train batch: 114 / 114 - loss: 0.00121 - accuracy: 0.993 - precision: 0.998 - recall: 0.993 - f1: 0.995\n",
            "Valid batch: 19 / 19 - loss: 0.00679 - accuracy: 0.922 - precision: 0.972 - recall: 0.922 - f1: 0.945\n",
            "\t=> Train epoch: loss: 0.0012 - accuracy: 0.988 - precision: 0.997 - recall: 0.989 - f1: 0.993\n",
            "\t=> Valid epoch: loss: 0.00702 - accuracy: 0.927 - precision: 0.972 - recall: 0.927 - f1: 0.948\n",
            "\t=> Learning Rate: : 0.000125 - Time: 0:00:53/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 8\n",
            "Train batch: 114 / 114 - loss: 0.00097 - accuracy: 0.993 - precision: 0.999 - recall: 0.993 - f1: 0.996\n",
            "Valid batch: 19 / 19 - loss: 0.00803 - accuracy: 0.922 - precision: 0.964 - recall: 0.923 - f1: 0.942\n",
            "\t=> Train epoch: loss: 0.00102 - accuracy: 0.991 - precision: 0.998 - recall: 0.991 - f1: 0.994\n",
            "\t=> Valid epoch: loss: 0.00702 - accuracy: 0.928 - precision: 0.972 - recall: 0.928 - f1: 0.949\n",
            "\t=> Learning Rate: : 0.000125 - Time: 0:00:53/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 9\n",
            "Train batch: 114 / 114 - loss: 0.00081 - accuracy: 0.996 - precision: 0.999 - recall: 0.996 - f1: 0.997\n",
            "Valid batch: 19 / 19 - loss: 0.00691 - accuracy: 0.923 - precision: 0.975 - recall: 0.923 - f1: 0.947\n",
            "\t=> Train epoch: loss: 0.00086 - accuracy: 0.993 - precision: 0.998 - recall: 0.993 - f1: 0.995\n",
            "\t=> Valid epoch: loss: 0.00703 - accuracy: 0.929 - precision: 0.973 - recall: 0.929 - f1: 0.949\n",
            "\t=> Learning Rate: : 6.25e-05 - Time: 0:00:53/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 10\n",
            "Train batch: 114 / 114 - loss: 0.00061 - accuracy: 0.997 - precision: 0.999 - recall: 0.997 - f1: 0.998\n",
            "Valid batch: 19 / 19 - loss: 0.00731 - accuracy: 0.928 - precision: 0.969 - recall: 0.929 - f1: 0.947\n",
            "\t=> Train epoch: loss: 0.00079 - accuracy: 0.994 - precision: 0.999 - recall: 0.994 - f1: 0.996\n",
            "\t=> Valid epoch: loss: 0.00712 - accuracy: 0.928 - precision: 0.972 - recall: 0.929 - f1: 0.949\n",
            "\t=> Learning Rate: : 6.25e-05 - Time: 0:00:53/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 11\n",
            "Train batch: 114 / 114 - loss: 0.00112 - accuracy: 0.993 - precision: 0.997 - recall: 0.993 - f1: 0.994\n",
            "Valid batch: 19 / 19 - loss: 0.00775 - accuracy: 0.93 - precision: 0.969 - recall: 0.93 - f1: 0.948\n",
            "\t=> Train epoch: loss: 0.00071 - accuracy: 0.994 - precision: 0.999 - recall: 0.994 - f1: 0.997\n",
            "\t=> Valid epoch: loss: 0.00707 - accuracy: 0.93 - precision: 0.972 - recall: 0.93 - f1: 0.95\n",
            "\t=> Learning Rate: : 3.125e-05 - Time: 0:00:52/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 12\n",
            "Train batch: 114 / 114 - loss: 0.00072 - accuracy: 0.995 - precision: 0.998 - recall: 0.995 - f1: 0.996\n",
            "Valid batch: 19 / 19 - loss: 0.00578 - accuracy: 0.942 - precision: 0.979 - recall: 0.942 - f1: 0.96\n",
            "\t=> Train epoch: loss: 0.00067 - accuracy: 0.995 - precision: 0.999 - recall: 0.995 - f1: 0.997\n",
            "\t=> Valid epoch: loss: 0.00712 - accuracy: 0.93 - precision: 0.972 - recall: 0.93 - f1: 0.95\n",
            "\t=> Learning Rate: : 3.125e-05 - Time: 0:00:53/step\n",
            "\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 13\n",
            "Train batch: 91 / 114 - loss: 0.00063 - accuracy: 0.995 - precision: 1.0 - recall: 0.995 - f1: 0.997"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-7-460b716a5707>\", line 157, in fit\n",
            "    self.forward(train_loader)\n",
            "  File \"<ipython-input-7-460b716a5707>\", line 106, in forward\n",
            "    acc = self.compute_metrics(logits, labels)\n",
            "  File \"<ipython-input-7-460b716a5707>\", line 59, in compute_metrics\n",
            "    labels = labels.cpu().detach().numpy()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-19-149afa5f960b>\", line 1, in <cell line: 1>\n",
            "    trainer.fit(train_loader, valid_loader, 20, \"./checkpoint/model_v1.pt\")\n",
            "  File \"<ipython-input-7-460b716a5707>\", line 163, in fit\n",
            "    sys.exit()\n",
            "SystemExit\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-460b716a5707>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, valid_loader, epochs, checkpoint)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-460b716a5707>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dataloader, train_mode)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mloss_his\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-460b716a5707>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(self, preds, labels)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-149afa5f960b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./checkpoint/model_v1.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-460b716a5707>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, valid_loader, epochs, checkpoint)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRlXy5SM6Ktw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}